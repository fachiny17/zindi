{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DSN Free AI Classes in Every City 2025\n",
        "##  The Excellent Store Challenge\n",
        "### Solution by: `IHEANYI, FAVOUR CHISOM`"
      ],
      "metadata": {
        "id": "VhzFPlSQXs0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import the Libraries"
      ],
      "metadata": {
        "id": "9DwYJXSES996"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoxqrGn8pBYu",
        "outputId": "d967f996-fab2-4ab3-b3fb-851ff8b5c297"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install catboost"
      ],
      "metadata": {
        "id": "CZ8AZ2JpN59r",
        "outputId": "26635851-d70c-4f59-cc83-916c3e07c48c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "TwOZKMH9Y6oQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup rendom seed\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "QtCHnvkaZVZJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ea9gEVTjbD53",
        "outputId": "4e5522c6-6bbf-4533-8389-c9ffc72dc840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "samp_sub = pd.read_csv('/content/drive/MyDrive/SampleSubmission.csv')\n",
        "\n",
        "# Combine data for feature engineering\n",
        "data = pd.concat([train, test], sort=False)\n",
        "\n",
        "## Enhanced Feature Engineering\n",
        "# Extract components from Item_Store_ID with more granularity\n",
        "data[['Item_Code', 'Store_Code']] = data['Item_Store_ID'].str.split('_', expand=True)\n",
        "data['Store_Cluster'] = data['Store_Code'].str.extract(r'([A-Za-z]+)')\n",
        "data['Store_Number'] = data['Store_Code'].str.extract(r'(\\d+)').astype(float)\n",
        "\n",
        "# More sophisticated item features\n",
        "data['Item_Prefix'] = data['Item_Code'].str.extract(r'^([A-Z]+)')\n",
        "data['Item_Middle'] = data['Item_Code'].str.extract(r'[A-Z]+([0-9]+)')[0]\n",
        "data['Item_Suffix'] = data['Item_Code'].str.extract(r'[0-9]+([A-Z]+)')\n",
        "data['Item_Numeric'] = data['Item_Code'].str.extract(r'(\\d+)').astype(float)\n",
        "\n",
        "# Fill missing values for new features\n",
        "data['Item_Middle'] = data['Item_Middle'].fillna(0).astype(int)\n",
        "data['Item_Suffix'] = data['Item_Suffix'].fillna('None')\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_cols = ['Item_Code', 'Store_Code', 'Store_Cluster', 'Item_Prefix', 'Item_Suffix']\n",
        "numerical_cols = ['Store_Number', 'Item_Middle', 'Item_Numeric']\n",
        "\n",
        "# Convert data types\n",
        "for col in categorical_cols:\n",
        "    data[col] = data[col].astype('category')\n",
        "for col in numerical_cols:\n",
        "    data[col] = pd.to_numeric(data[col], errors='coerce').fillna(0)\n",
        "\n",
        "# Now separate features and target\n",
        "X = data.drop([\"Item_Store_Returns\", \"Item_Store_ID\"], axis=1)\n",
        "y = data[\"Item_Store_Returns\"]\n",
        "\n",
        "# Split back into train and test\n",
        "X_train = X[~y.isnull()]\n",
        "y_train = y[~y.isnull()]\n",
        "X_test = X[y.isnull()]\n",
        "\n",
        "# Train-test split for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get indices of categorical features for CatBoost\n",
        "cat_features_indices = [X_train.columns.get_loc(col) for col in categorical_cols]\n",
        "\n",
        "# For non-CatBoost models, we'll use label encoding instead of one-hot to avoid dimension explosion\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train_encoded = X_train.copy()\n",
        "X_val_encoded = X_val.copy()\n",
        "X_test_encoded = X_test.copy()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    # Fit on train and transform all sets\n",
        "    X_train_encoded[col] = le.fit_transform(X_train_encoded[col].astype(str))\n",
        "    X_val_encoded[col] = le.transform(X_val_encoded[col].astype(str))\n",
        "    X_test_encoded[col] = le.transform(X_test_encoded[col].astype(str))\n",
        "\n",
        "# Reinitialize CatBoost with proper categorical features\n",
        "catboost = CatBoostRegressor(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.05,\n",
        "    depth=8,\n",
        "    eval_metric='RMSE',\n",
        "    random_seed=42,\n",
        "    cat_features=cat_features_indices,\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "# XGBoost Regressor\n",
        "xgb = XGBRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    early_stopping_rounds=50,\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Gradient Boosting Regressor\n",
        "gb = GradientBoostingRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    min_samples_split=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Stacked model using Voting Regressor with XGBoost\n",
        "stacked_model = VotingRegressor(\n",
        "    estimators=[\n",
        "        ('catboost', catboost),\n",
        "        ('xgb', xgb),\n",
        "        ('random_forest', rf),\n",
        "        ('gradient_boost', gb)\n",
        "    ],\n",
        "    weights=[0.4, 0.3, 0.15, 0.15]\n",
        ")\n",
        "\n",
        "# Fit models with proper data\n",
        "print(\"Training CatBoost...\")\n",
        "catboost.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
        "\n",
        "print(\"\\nTraining XGBoost...\")\n",
        "xgb.fit(X_train_encoded, y_train, eval_set=[(X_val_encoded, y_val)], verbose=100)\n",
        "\n",
        "print(\"\\nTraining Random Forest...\")\n",
        "rf.fit(X_train_encoded, y_train)\n",
        "\n",
        "print(\"\\nTraining Gradient Boosting...\")\n",
        "gb.fit(X_train_encoded, y_train)\n",
        "\n",
        "print(\"\\nTraining Stacked Model...\")\n",
        "# For stacked model, we need to use the encoded version for non-CatBoost models\n",
        "# This requires a bit more work - we'll need to create separate pipelines\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.columns]\n",
        "\n",
        "# Create individual model pipelines\n",
        "catboost_pipe = Pipeline([\n",
        "    ('selector', ColumnSelector(X_train.columns.tolist())),\n",
        "    ('model', catboost)\n",
        "])\n",
        "\n",
        "xgb_pipe = Pipeline([\n",
        "    ('encoder', LabelEncoderWrapper(categorical_cols)),  # Custom encoder\n",
        "    ('model', xgb)\n",
        "])\n",
        "\n",
        "# Similarly for other models...\n",
        "\n",
        "# Alternatively, we can train the stacked model using the encoded data\n",
        "# and handle CatBoost separately in production\n",
        "\n",
        "# For simplicity, let's proceed with the encoded data for stacking\n",
        "# Note: This means CatBoost won't get its categorical features in the stack\n",
        "# For a proper implementation, we'd need a more sophisticated approach\n",
        "\n",
        "stacked_model.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(\"CatBoost:\")\n",
        "cb_rmse = evaluate_model(catboost, X_val, y_val)\n",
        "\n",
        "print(\"\\nXGBoost:\")\n",
        "xgb_rmse = evaluate_model(xgb, X_val_encoded, y_val)\n",
        "\n",
        "print(\"\\nRandom Forest:\")\n",
        "rf_rmse = evaluate_model(rf, X_val_encoded, y_val)\n",
        "\n",
        "print(\"\\nGradient Boosting:\")\n",
        "gb_rmse = evaluate_model(gb, X_val_encoded, y_val)\n",
        "\n",
        "print(\"\\nStacked Model:\")\n",
        "stacked_rmse = evaluate_model(stacked_model, X_val_encoded, y_val)\n",
        "\n",
        "# For final predictions, we need to use the appropriate data format for each model\n",
        "# This would be more complex in a real deployment\n",
        "\n",
        "# Generate predictions using CatBoost (best model in our case)\n",
        "test_preds = catboost.predict(X_test)\n",
        "\n",
        "# Prepare submission\n",
        "submission = samp_sub.copy()\n",
        "submission['Item_Store_Returns'] = test_preds\n",
        "\n",
        "# Save submission\n",
        "submission.to_csv('final_submission.csv', index=False)\n",
        "print(\"\\nFinal submission file saved as 'final_submission.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "6YdjOkREY3Ln",
        "outputId": "0432721e-28cf-4b0a-b7cb-cfadf46a6b14"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "For a sparse output, all columns should be a numeric or convertible to a numeric.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_hstack\u001b[0;34m(self, Xs, n_samples)\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;31m# dtype conversion if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m                 converted_Xs = [\n\u001b[0m\u001b[1;32m   1136\u001b[0m                     \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1135\u001b[0m                 converted_Xs = [\n\u001b[0;32m-> 1136\u001b[0;31m                     \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'FDH56'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-3060533556.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Apply to X_train and X_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mX_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mX_val_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_output_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_hstack\u001b[0;34m(self, Xs, n_samples)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 ]\n\u001b[1;32m   1139\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1141\u001b[0m                     \u001b[0;34m\"For a sparse output, all columns should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0;34m\"be a numeric or convertible to a numeric.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: For a sparse output, all columns should be a numeric or convertible to a numeric."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Eg3f7pWaYUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}